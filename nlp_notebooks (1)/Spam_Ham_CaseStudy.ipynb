{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"Spam_Ham_CaseStudy.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"thyRCB0p8qcl","colab_type":"code","colab":{}},"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","import pandas as pd\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZt5N-sq8qcr","colab_type":"code","colab":{}},"source":["os.chdir('E:\\\\Profond Ananlytics\\\\SPAM-HAM')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjgRCIp78qcu","colab_type":"code","colab":{},"outputId":"b172d7c0-889d-4ac5-e65c-0b85f2f889d7"},"source":["df=pd.read_csv('spam.csv', encoding='latin-1')\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1                                                 v2 Unnamed: 2  \\\n","0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n","1   ham                      Ok lar... Joking wif u oni...        NaN   \n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n","3   ham  U dun say so early hor... U c already then say...        NaN   \n","4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n","\n","  Unnamed: 3 Unnamed: 4  \n","0        NaN        NaN  \n","1        NaN        NaN  \n","2        NaN        NaN  \n","3        NaN        NaN  \n","4        NaN        NaN  "]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"fivx1wMx8qcy","colab_type":"code","colab":{},"outputId":"ba6fe8fc-dd1c-4e17-f897-e4ca98ef6b32"},"source":["df=df[['v1', 'v2']]\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1                                                 v2\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro..."]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Utw-gBhd8qc1","colab_type":"code","colab":{},"outputId":"9a26df90-0f8e-4809-9d53-831106c09fd8"},"source":["#Text pre processing\n","#convert to lower case\n","\n","df['v2']=df['v2'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>go until jurong point, crazy.. available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>ok lar... joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>u dun say so early hor... u c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>nah i don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1                                                 v2\n","0   ham  go until jurong point, crazy.. available only ...\n","1   ham                      ok lar... joking wif u oni...\n","2  spam  free entry in 2 a wkly comp to win fa cup fina...\n","3   ham  u dun say so early hor... u c already then say...\n","4   ham  nah i don't think he goes to usf, he lives aro..."]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"2bAHaON48qc3","colab_type":"code","colab":{},"outputId":"b3463284-e831-4d00-8d80-285a33ee168e"},"source":["#replace special characters\n","df['v2']=df['v2'].str.replace('[^\\w\\s]','')\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>go until jurong point crazy available only in ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>ok lar joking wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>u dun say so early hor u c already then say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>nah i dont think he goes to usf he lives aroun...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1                                                 v2\n","0   ham  go until jurong point crazy available only in ...\n","1   ham                            ok lar joking wif u oni\n","2  spam  free entry in 2 a wkly comp to win fa cup fina...\n","3   ham        u dun say so early hor u c already then say\n","4   ham  nah i dont think he goes to usf he lives aroun..."]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Ed9doNsu8qc6","colab_type":"code","colab":{},"outputId":"0c04e449-c587-40dc-e6f4-e552e1232100"},"source":["#remove stop words\n","stop=stopwords.words('english')\n","df['v2']=df['v2'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>go jurong point crazy available bugis n great ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>ok lar joking wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>u dun say early hor u c already say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>nah dont think goes usf lives around though</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1                                                 v2\n","0   ham  go jurong point crazy available bugis n great ...\n","1   ham                            ok lar joking wif u oni\n","2  spam  free entry 2 wkly comp win fa cup final tkts 2...\n","3   ham                u dun say early hor u c already say\n","4   ham        nah dont think goes usf lives around though"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"bOSnHUw28qc9","colab_type":"code","colab":{},"outputId":"46d2a02d-406b-4a8f-ccf8-a696928273c9"},"source":["#stemming\n","st=PorterStemmer()\n","df['v2']=df['v2'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>go jurong point crazi avail bugi n great world...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>ok lar joke wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>u dun say earli hor u c alreadi say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>nah dont think goe usf live around though</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1                                                 v2\n","0   ham  go jurong point crazi avail bugi n great world...\n","1   ham                              ok lar joke wif u oni\n","2  spam  free entri 2 wkli comp win fa cup final tkt 21...\n","3   ham                u dun say earli hor u c alreadi say\n","4   ham          nah dont think goe usf live around though"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"hus0vi_S8qc_","colab_type":"code","colab":{},"outputId":"1d5e5e1a-1c3a-410d-cbff-64ce2f42c2ca"},"source":["#lemmatization\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer=WordNetLemmatizer()\n","\n","df['v2']=df['v2'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>go jurong point crazi avail bugi n great world...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>ok lar joke wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>u dun say earli hor u c alreadi say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>nah dont think goe usf live around though</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1                                                 v2\n","0   ham  go jurong point crazi avail bugi n great world...\n","1   ham                              ok lar joke wif u oni\n","2  spam  free entri 2 wkli comp win fa cup final tkt 21...\n","3   ham                u dun say earli hor u c alreadi say\n","4   ham          nah dont think goe usf live around though"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"tzYYTYp88qdB","colab_type":"code","colab":{},"outputId":"35fd7b39-12ab-45a0-e081-6a1649ab5f59"},"source":["#tokenization\n","df['v2']=df.apply(lambda x: word_tokenize(x['v2']), axis=1)\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>[ok, lar, joke, wif, u, oni]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1                                                 v2\n","0   ham  [go, jurong, point, crazi, avail, bugi, n, gre...\n","1   ham                       [ok, lar, joke, wif, u, oni]\n","2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...\n","3   ham      [u, dun, say, earli, hor, u, c, alreadi, say]\n","4   ham  [nah, dont, think, goe, usf, live, around, tho..."]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"bT4xHqYq8qdD","colab_type":"code","colab":{}},"source":["df['v2']=[\" \".join(x) for x in df['v2'].values]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKBhuxSs8qdF","colab_type":"code","colab":{},"outputId":"86276358-3624-49b4-85a2-09eff8c8711d"},"source":["df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>go jurong point crazi avail bugi n great world...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>ok lar joke wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>u dun say earli hor u c alreadi say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>nah dont think goe usf live around though</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1                                                 v2\n","0   ham  go jurong point crazi avail bugi n great world...\n","1   ham                              ok lar joke wif u oni\n","2  spam  free entri 2 wkli comp win fa cup final tkt 21...\n","3   ham                u dun say earli hor u c alreadi say\n","4   ham          nah dont think goe usf live around though"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"izVY7FEd8qdH","colab_type":"code","colab":{},"outputId":"865ed763-c1fa-458e-d8bc-6eaf2cee7f4c"},"source":["from sklearn.model_selection import train_test_split\n","\n","xtrain, xtest, ytrain, ytest= train_test_split(df['v2'], df['v1'], test_size=0.3, random_state=100)\n","\n","print(xtrain.shape)\n","print(xtest.shape)\n","print(ytrain.shape)\n","print(ytest.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(3900,)\n","(1672,)\n","(3900,)\n","(1672,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_-iferwZ8qdJ","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder\n","lb = LabelEncoder()\n","ytrain=lb.fit_transform(ytrain)\n","ytest=lb.transform(ytest)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8BwK7OBo8qdL","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","\n","tfvect=TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n","tfvect=tfvect.fit(df['v2'])\n","\n","xtrain_new=tfvect.transform(xtrain)\n","xtest_new=tfvect.transform(xtest)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFsjFOkW8qdN","colab_type":"code","colab":{},"outputId":"5789e591-1dad-4937-a8ee-3177fddab33d"},"source":["xtrain_new"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<3900x5000 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 33035 stored elements in Compressed Sparse Row format>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"HVZ17sNz8qdQ","colab_type":"code","colab":{}},"source":["def train_model(classifier, xtrain, ytrain, xtest, ytest):\n","    mod=classifier.fit(xtrain, ytrain)\n","    predictions=mod.predict(xtest)\n","    accuracy=accuracy_score(ytest, predictions)\n","    return accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MznGVKsj8qdR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"op9b7rkw8qdW","colab_type":"code","colab":{},"outputId":"84dbbb89-c565-4428-8fc9-f57183112359"},"source":["from sklearn import naive_bayes\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","accuracy1 = train_model(naive_bayes.MultinomialNB(), xtrain_new, ytrain, xtest_new, ytest)\n","\n","print(accuracy1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.965311004784689\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ixk1To8e8qdY","colab_type":"code","colab":{},"outputId":"bd91cf84-a8fb-47bc-83b2-09b897c47b6d"},"source":["\n","\n","accuracy = train_model(LogisticRegression(), xtrain_new, ytrain, xtest_new, ytest)\n","\n","print(accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["0.9581339712918661\n"],"name":"stdout"}]}]}